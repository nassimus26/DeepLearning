{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearPolicy:\n",
    "    def __init__(\n",
    "        self, parameters: np.ndarray, features: Callable[[np.ndarray], np.ndarray]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Linear Policy Constructor.\n",
    "        \n",
    "        Args:\n",
    "            parameters (np.ndarray): policy parameters as np.ndarray.\n",
    "            features (np.ndarray): features to be extracted from the state representation.\n",
    "        \"\"\"\n",
    "        self._parameters = parameters\n",
    "        self._features = features\n",
    "\n",
    "    def __call__(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Call method of the Policy.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): environment state.\n",
    "        \n",
    "        Returns:\n",
    "            The resulting action.\n",
    "        \"\"\"\n",
    "\n",
    "        # calculate state features\n",
    "        state_features = self._features(state)\n",
    "\n",
    "        # the parameters shape [0] should be the same as the state features\n",
    "        # as they must be multiplied\n",
    "        assert state_features.shape[0] == self._parameters.shape[0]\n",
    "\n",
    "        # dot product between parameters and state features\n",
    "        return np.dot(self._parameters.T, state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.33244481]]\n"
     ]
    }
   ],
   "source": [
    "# sample a random set of parameters\n",
    "parameters = np.random.rand(5, 1)\n",
    "\n",
    "# define the state features as identity function\n",
    "features = lambda x: x\n",
    "\n",
    "# define the policy\n",
    "pi: LinearPolicy = LinearPolicy(parameters, features)\n",
    "\n",
    "# sample a state\n",
    "state = np.random.rand(5, 1)\n",
    "\n",
    "# Call the policy obtaining the action\n",
    "action = pi(state)\n",
    "\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPolicy:\n",
    "    def __init__(\n",
    "        self,\n",
    "        mu_parameters: np.ndarray,\n",
    "        sigma_parameters: np.ndarray,\n",
    "        features: Callable[[np.ndarray], np.ndarray],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Linear Policy Constructor.\n",
    "        \n",
    "        Args:\n",
    "            mu_parameters (np.ndarray): policy parameters of the mean (\\mu) as np.ndarray.\n",
    "            sigma_parameters (np.ndarray): policy parameters of the standard deviation as np.ndarray.\n",
    "            features (np.ndarray): features to be extracted from the state representation.\n",
    "        \"\"\"\n",
    "        self._mu_parameters = mu_parameters\n",
    "        self._sigma_parameters = sigma_parameters\n",
    "        self._features = features\n",
    "\n",
    "    def __call__(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Call method of the Policy.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): environment state.\n",
    "        \n",
    "        Returns:\n",
    "            The action sampled from the policy distribution.\n",
    "        \"\"\"\n",
    "\n",
    "        # calculate state features\n",
    "        state_features = self._features(state)\n",
    "\n",
    "        # the parameters shape [0] should be the same as the state features\n",
    "        # as they must be multiplied\n",
    "        assert state_features.shape[0] == self._mu_parameters.shape[0]\n",
    "        assert state_features.shape[0] == self._sigma_parameters.shape[0]\n",
    "\n",
    "        # dot product between parameters and state features\n",
    "        # \\mu is the mean of the gaussian\n",
    "        mu = np.dot(self._mu_parameters.T, state_features)\n",
    "        # the stddev (sigma) should be squared to avoid negative numbers\n",
    "        sigma = np.dot(self._sigma_parameters.T, state_features) ** 2\n",
    "\n",
    "        # sample action from gaussian distribution\n",
    "        action = np.random.normal(mu, sigma)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def mu(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Mean of the distribution in the current state.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): environment state.\n",
    "        \n",
    "        Returns:\n",
    "            mu: mean of the Gaussian distribution.\n",
    "        \"\"\"\n",
    "        # calculate state features\n",
    "        state_features = self._features(state)\n",
    "\n",
    "        # the parameters shape [0] should be the same as the state features\n",
    "        # as they must be multiplied\n",
    "        assert state_features.shape[0] == self._mu_parameters.shape[0]\n",
    "\n",
    "        return np.dot(self._mu_parameters.T, state_features)\n",
    "\n",
    "    def sigma(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Stddev of the distribution in the current state.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): environment state.\n",
    "            \n",
    "        Returns:\n",
    "            sigma: stddev of the Gaussian distribution.\n",
    "        \"\"\"\n",
    "        # calculate state features\n",
    "        state_features = self._features(state)\n",
    "\n",
    "        # the parameters shape [0] should be the same as the state features\n",
    "        # as they must be multiplied\n",
    "        assert state_features.shape[0] == self._sigma_parameters.shape[0]\n",
    "\n",
    "        return np.dot(self._sigma_parameters.T, state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.80702857]]\n"
     ]
    }
   ],
   "source": [
    "# sample a random set of parameters\n",
    "mu_parameters = np.random.rand(5, 1)\n",
    "sigma_parameters = np.random.rand(5, 1)\n",
    "\n",
    "# define the state features as identity function\n",
    "features = lambda x: x\n",
    "\n",
    "# define the policy\n",
    "pi: GaussianPolicy = GaussianPolicy(mu_parameters, sigma_parameters, features)\n",
    "\n",
    "# sample a state\n",
    "state = np.random.rand(5, 1)\n",
    "\n",
    "# Call the policy obtaining the action\n",
    "action = pi(state)\n",
    "\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12095ca58>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 100\n",
    "\n",
    "samples = []\n",
    "\n",
    "# sample action from the policy and append them to the samples array\n",
    "for _ in range(n_samples):\n",
    "    samples.append(pi(state).flatten()[0])\n",
    "\n",
    "# reduce the plot size\n",
    "plt.ylim(-1e-3, 0.5)\n",
    "# plot the samples on the x axis\n",
    "plt.scatter(samples, np.zeros_like(samples))\n",
    "\n",
    "# plot the distribution\n",
    "mu = pi.mu(state).flatten()[0]\n",
    "sigma = pi.sigma(state).flatten()[0]\n",
    "x = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\n",
    "plt.plot(x, scipy.stats.norm.pdf(x, mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoltzmannPolicy:\n",
    "    def __init__(\n",
    "        self, parameters: List[np.ndarray], features: Callable[[np.ndarray], np.ndarray]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Linear Policy Constructor.\n",
    "        \n",
    "        Args:\n",
    "            parameters (List[np.ndarray]): policy parameters for each action as np.ndarray.\n",
    "            features (np.ndarray): features to be extracted from the state representation.\n",
    "        \"\"\"\n",
    "        self._parameters = parameters\n",
    "        self._features = features\n",
    "        self._n_actions = len(self._parameters)\n",
    "\n",
    "    def __call__(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Call method of the Policy.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): environment state.\n",
    "            \n",
    "        Returns:\n",
    "            action: Action sampled from the action probabilities.\n",
    "        \"\"\"\n",
    "\n",
    "        # calculate state features\n",
    "        state_features = self._features(state)\n",
    "\n",
    "        # the parameters shape [0] should be the same as the state features\n",
    "        # as they must be multiplied\n",
    "        for action_params in self._parameters:\n",
    "            assert state_features.shape[0] == action_params.shape[0]\n",
    "\n",
    "        # calculate scores for each action\n",
    "        scores = []\n",
    "        for action_params in self._parameters:\n",
    "            score = np.dot(action_params.T, state_features)[0, 0]\n",
    "            scores.append(score)\n",
    "\n",
    "        # use scipy softmax function\n",
    "        action_probs = scipy.special.softmax(scores)\n",
    "\n",
    "        # sample the action according to the probabilities\n",
    "        action = np.random.choice(self._n_actions, p=action_probs)\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Action is 1\n",
      "Selected action is 1\n",
      "Selected action is 2\n",
      "Selected action is 1\n",
      "Selected action is 0\n",
      "Selected action is 2\n",
      "Selected action is 2\n",
      "Selected action is 1\n",
      "Selected action is 0\n",
      "Selected action is 0\n",
      "Selected action is 1\n"
     ]
    }
   ],
   "source": [
    "n_actions = 3\n",
    "# sample a random set of parameters for each action\n",
    "parameters = [np.random.rand(5, 1) for _ in range(n_actions)]\n",
    "\n",
    "# define the state features as identity function\n",
    "features = lambda x: x\n",
    "\n",
    "# define the policy\n",
    "pi: BoltzmannPolicy = BoltzmannPolicy(parameters, features)\n",
    "\n",
    "# sample a state\n",
    "state = np.random.rand(5, 1)\n",
    "\n",
    "# Call the policy obtaining the action\n",
    "action = pi(state)\n",
    "print(\"Selected Action is\", action)\n",
    "\n",
    "# sample some actions\n",
    "for _ in range(10):\n",
    "    print(\"Selected action is\", pi(state))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
