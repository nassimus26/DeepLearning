{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.ppo2.ppo2 import learn\n",
    "from baselines.ppo2 import defaults\n",
    "from baselines.common.vec_env import VecEnv, VecFrameStack\n",
    "from baselines.common.cmd_util import make_vec_env, make_env\n",
    "from baselines.common.models import register\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register(\"custom_cnn\")\n",
    "def custom_cnn():\n",
    "    def network_fn(input_shape, **conv_kwargs):\n",
    "        \"\"\"\n",
    "        Custom CNN\n",
    "        \"\"\"\n",
    "        print('input shape is {}'.format(input_shape))\n",
    "        x_input = tf.keras.Input(shape=input_shape, dtype=tf.uint8)\n",
    "        h = x_input\n",
    "        h = tf.cast(h, tf.float32) / 255.\n",
    "        \n",
    "        h = tf.keras.layers.Conv2D(filters=32, kernel_size=8, strides=4, padding='valid',\n",
    "                                   data_format='channels_last', activation='relu')(h)\n",
    "        h2 = tf.keras.layers.Conv2D(filters=64, kernel_size=4, strides=2, padding='valid',\n",
    "                                   data_format='channels_last', activation='relu')(h)\n",
    "        h3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='valid',\n",
    "                                   data_format='channels_last', activation='relu')(h2)        \n",
    "        h3 = tf.keras.layers.Flatten()(h3)\n",
    "        h3 = tf.keras.layers.Dense(units=512, name='fc1', activation='relu')(h3)\n",
    "        \n",
    "        network = tf.keras.Model(inputs=[x_input], outputs=[h3])\n",
    "        network.summary()\n",
    "        return network\n",
    "\n",
    "    return network_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_env(env_id, env_type):\n",
    "\n",
    "    if env_type in {'atari', 'retro'}:\n",
    "        env = make_vec_env(env_id, env_type, 1, None, gamestate=None, reward_scale=1.0)\n",
    "        env = VecFrameStack(env, 4)\n",
    "\n",
    "    else:\n",
    "        env = make_vec_env(env_id, env_type, 1, None, reward_scale=1.0, flatten_dict_observations=True)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env type =  atari\n",
      "Logging to /tmp/openai-2020-05-11-16-19-42-770612\n",
      "input shape is (84, 84, 4)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlow [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_truediv (TensorF [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               1606144   \n",
      "=================================================================\n",
      "Total params: 1,684,128\n",
      "Trainable params: 1,684,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "--------------------------------------------\n",
      "| eplenmean               | 1e+03          |\n",
      "| eprewmean               | -20            |\n",
      "| fps                     | 213            |\n",
      "| loss/approxkl           | 0.00012817292  |\n",
      "| loss/clipfrac           | 0.0            |\n",
      "| loss/policy_entropy     | 1.7916294      |\n",
      "| loss/policy_loss        | -0.00050599687 |\n",
      "| loss/value_loss         | 0.06880974     |\n",
      "| misc/explained_variance | 0.000675       |\n",
      "| misc/nupdates           | 1              |\n",
      "| misc/serial_timesteps   | 2048           |\n",
      "| misc/time_elapsed       | 9.6            |\n",
      "| misc/total_timesteps    | 2048           |\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env_id = 'PongNoFrameskip-v0'\n",
    "env_type = 'atari'\n",
    "print(\"Env type = \", env_type)\n",
    "\n",
    "env = build_env(env_id, env_type)\n",
    "\n",
    "model = learn(network=\"custom_cnn\", env=env, total_timesteps=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [0.]\n",
      "Reward =  [-1.]\n",
      "Episode Reward = [-17.]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "if not isinstance(env, VecEnv):\n",
    "    obs = np.expand_dims(np.array(obs), axis=0)\n",
    "\n",
    "episode_rew = 0\n",
    "    \n",
    "while True:\n",
    "    actions, _, state, _ = model.step(obs)\n",
    "    obs, reward, done, info = env.step(actions.numpy())\n",
    "    if not isinstance(env, VecEnv):\n",
    "        obs = np.expand_dims(np.array(obs), axis=0)\n",
    "    env.render()\n",
    "    print(\"Reward = \", reward)\n",
    "    episode_rew += reward\n",
    "    \n",
    "    if done:\n",
    "        print('Episode Reward = {}'.format(episode_rew))\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/Pong/\n",
      "env_type: atari\n",
      "Training ppo2 on atari:PongNoFrameskip-v0 with arguments \n",
      "{'nsteps': 128, 'nminibatches': 4, 'lam': 0.95, 'gamma': 0.99, 'noptepochs': 4, 'log_interval': 1, 'ent_coef': 0.01, 'lr': <function atari.<locals>.<lambda> at 0x7f5e0ec33950>, 'cliprange': 0.1, 'network': 'cnn'}\n",
      "input shape is (84, 84, 4)\n",
      "2020-05-11 16:18:14.491437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-05-11 16:18:14.508280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.508628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2020-05-11 16:18:14.508836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:18:14.510313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:18:14.511828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-05-11 16:18:14.512132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-05-11 16:18:14.513568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-05-11 16:18:14.514753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-05-11 16:18:14.520089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-11 16:18:14.520719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.521119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.521378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-05-11 16:18:14.521710: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-11 16:18:14.545966: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2020-05-11 16:18:14.546276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56164e81a380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-11 16:18:14.546323: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-11 16:18:14.546585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.546950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2020-05-11 16:18:14.547185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:18:14.547209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:18:14.547224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-05-11 16:18:14.547239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-05-11 16:18:14.547253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-05-11 16:18:14.547267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-05-11 16:18:14.547283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-11 16:18:14.547413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.547771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.547976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-05-11 16:18:14.548017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:18:14.590032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-05-11 16:18:14.590059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2020-05-11 16:18:14.590066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2020-05-11 16:18:14.590247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.590574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.590843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:14.591095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2020-05-11 16:18:14.592840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561651657520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-11 16:18:14.593060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1\n",
      "Stepping environment...\n",
      "2020-05-11 16:18:16.005779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:18:16.165020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-11 16:18:18.085070: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "-------------------------------------------\n",
      "| eplenmean               | nan           |\n",
      "| eprewmean               | nan           |\n",
      "| fps                     | 144           |\n",
      "| loss/approxkl           | 0.0033949534  |\n",
      "| loss/clipfrac           | 0.21191406    |\n",
      "| loss/policy_entropy     | 1.7889717     |\n",
      "| loss/policy_loss        | -0.0017111386 |\n",
      "| loss/value_loss         | 2.8520613     |\n",
      "| misc/explained_variance | -0.156        |\n",
      "| misc/nupdates           | 1             |\n",
      "| misc/serial_timesteps   | 128           |\n",
      "| misc/time_elapsed       | 3.55          |\n",
      "| misc/total_timesteps    | 512           |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "--------------------------------------------\n",
      "| eplenmean               | nan            |\n",
      "| eprewmean               | nan            |\n",
      "| fps                     | 509            |\n",
      "| loss/approxkl           | 0.000985355    |\n",
      "| loss/clipfrac           | 0.0390625      |\n",
      "| loss/policy_entropy     | 1.7866873      |\n",
      "| loss/policy_loss        | -0.00015214668 |\n",
      "| loss/value_loss         | 0.14466678     |\n",
      "| misc/explained_variance | -0.00307       |\n",
      "| misc/nupdates           | 2              |\n",
      "| misc/serial_timesteps   | 256            |\n",
      "| misc/time_elapsed       | 4.56           |\n",
      "| misc/total_timesteps    | 1024           |\n",
      "--------------------------------------------\n",
      "Stepping environment...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| eplenmean               | nan           |\n",
      "| eprewmean               | nan           |\n",
      "| fps                     | 509           |\n",
      "| loss/approxkl           | 0.0012383936  |\n",
      "| loss/clipfrac           | 0.06542969    |\n",
      "| loss/policy_entropy     | 1.7830635     |\n",
      "| loss/policy_loss        | -0.0026924321 |\n",
      "| loss/value_loss         | 0.14634527    |\n",
      "| misc/explained_variance | 0.0318        |\n",
      "| misc/nupdates           | 3             |\n",
      "| misc/serial_timesteps   | 384           |\n",
      "| misc/time_elapsed       | 5.56          |\n",
      "| misc/total_timesteps    | 1536          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | nan           |\n",
      "| eprewmean               | nan           |\n",
      "| fps                     | 506           |\n",
      "| loss/approxkl           | 0.0017005616  |\n",
      "| loss/clipfrac           | 0.11328125    |\n",
      "| loss/policy_entropy     | 1.7736549     |\n",
      "| loss/policy_loss        | -0.0045759943 |\n",
      "| loss/value_loss         | 0.113557      |\n",
      "| misc/explained_variance | -0.0169       |\n",
      "| misc/nupdates           | 4             |\n",
      "| misc/serial_timesteps   | 512           |\n",
      "| misc/time_elapsed       | 6.57          |\n",
      "| misc/total_timesteps    | 2048          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | nan           |\n",
      "| eprewmean               | nan           |\n",
      "| fps                     | 507           |\n",
      "| loss/approxkl           | 0.00093085726 |\n",
      "| loss/clipfrac           | 0.022460938   |\n",
      "| loss/policy_entropy     | 1.7823309     |\n",
      "| loss/policy_loss        | -0.0016494063 |\n",
      "| loss/value_loss         | 0.12098918    |\n",
      "| misc/explained_variance | 0.00611       |\n",
      "| misc/nupdates           | 5             |\n",
      "| misc/serial_timesteps   | 640           |\n",
      "| misc/time_elapsed       | 7.58          |\n",
      "| misc/total_timesteps    | 2560          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | nan           |\n",
      "| eprewmean               | nan           |\n",
      "| fps                     | 511           |\n",
      "| loss/approxkl           | 0.0010201824  |\n",
      "| loss/clipfrac           | 0.0703125     |\n",
      "| loss/policy_entropy     | 1.7850317     |\n",
      "| loss/policy_loss        | -0.0034382301 |\n",
      "| loss/value_loss         | 0.10710556    |\n",
      "| misc/explained_variance | 0.00259       |\n",
      "| misc/nupdates           | 6             |\n",
      "| misc/serial_timesteps   | 768           |\n",
      "| misc/time_elapsed       | 8.59          |\n",
      "| misc/total_timesteps    | 3072          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 872           |\n",
      "| eprewmean               | -20.5         |\n",
      "| fps                     | 443           |\n",
      "| loss/approxkl           | 0.00036452198 |\n",
      "| loss/clipfrac           | 0.00390625    |\n",
      "| loss/policy_entropy     | 1.7856563     |\n",
      "| loss/policy_loss        | -0.0023508086 |\n",
      "| loss/value_loss         | 0.10410442    |\n",
      "| misc/explained_variance | -0.0511       |\n",
      "| misc/nupdates           | 7             |\n",
      "| misc/serial_timesteps   | 896           |\n",
      "| misc/time_elapsed       | 9.74          |\n",
      "| misc/total_timesteps    | 3584          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 872           |\n",
      "| eprewmean               | -20.5         |\n",
      "| fps                     | 473           |\n",
      "| loss/approxkl           | 0.0012559259  |\n",
      "| loss/clipfrac           | 0.033691406   |\n",
      "| loss/policy_entropy     | 1.7848216     |\n",
      "| loss/policy_loss        | -0.0019852968 |\n",
      "| loss/value_loss         | 0.059650876   |\n",
      "| misc/explained_variance | -0.0261       |\n",
      "| misc/nupdates           | 8             |\n",
      "| misc/serial_timesteps   | 1024          |\n",
      "| misc/time_elapsed       | 10.8          |\n",
      "| misc/total_timesteps    | 4096          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 872           |\n",
      "| eprewmean               | -20.5         |\n",
      "| fps                     | 497           |\n",
      "| loss/approxkl           | 0.001926166   |\n",
      "| loss/clipfrac           | 0.087890625   |\n",
      "| loss/policy_entropy     | 1.7735035     |\n",
      "| loss/policy_loss        | -0.0031070665 |\n",
      "| loss/value_loss         | 0.081951514   |\n",
      "| misc/explained_variance | 0.0229        |\n",
      "| misc/nupdates           | 9             |\n",
      "| misc/serial_timesteps   | 1152          |\n",
      "| misc/time_elapsed       | 11.9          |\n",
      "| misc/total_timesteps    | 4608          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 872           |\n",
      "| eprewmean               | -20.5         |\n",
      "| fps                     | 515           |\n",
      "| loss/approxkl           | 0.0018270034  |\n",
      "| loss/clipfrac           | 0.104003906   |\n",
      "| loss/policy_entropy     | 1.7851264     |\n",
      "| loss/policy_loss        | -0.0035204007 |\n",
      "| loss/value_loss         | 0.077528566   |\n",
      "| misc/explained_variance | 0.0299        |\n",
      "| misc/nupdates           | 10            |\n",
      "| misc/serial_timesteps   | 1280          |\n",
      "| misc/time_elapsed       | 12.8          |\n",
      "| misc/total_timesteps    | 5120          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 872           |\n",
      "| eprewmean               | -20.5         |\n",
      "| fps                     | 505           |\n",
      "| loss/approxkl           | 0.00054775475 |\n",
      "| loss/clipfrac           | 0.019042969   |\n",
      "| loss/policy_entropy     | 1.78444       |\n",
      "| loss/policy_loss        | -0.0019487955 |\n",
      "| loss/value_loss         | 0.07532541    |\n",
      "| misc/explained_variance | 0.0677        |\n",
      "| misc/nupdates           | 11            |\n",
      "| misc/serial_timesteps   | 1408          |\n",
      "| misc/time_elapsed       | 13.9          |\n",
      "| misc/total_timesteps    | 5632          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "--------------------------------------------\n",
      "| eplenmean               | 872            |\n",
      "| eprewmean               | -20.5          |\n",
      "| fps                     | 521            |\n",
      "| loss/approxkl           | 0.00085579173  |\n",
      "| loss/clipfrac           | 0.009277344    |\n",
      "| loss/policy_entropy     | 1.7774254      |\n",
      "| loss/policy_loss        | -0.00034736842 |\n",
      "| loss/value_loss         | 0.073353805    |\n",
      "| misc/explained_variance | 0.105          |\n",
      "| misc/nupdates           | 12             |\n",
      "| misc/serial_timesteps   | 1536           |\n",
      "| misc/time_elapsed       | 14.8           |\n",
      "| misc/total_timesteps    | 6144           |\n",
      "--------------------------------------------\n",
      "Stepping environment...\n",
      "--------------------------------------------\n",
      "| eplenmean               | 872            |\n",
      "| eprewmean               | -20.5          |\n",
      "| fps                     | 515            |\n",
      "| loss/approxkl           | 5.4622717e-05  |\n",
      "| loss/clipfrac           | 0.0            |\n",
      "| loss/policy_entropy     | 1.7856551      |\n",
      "| loss/policy_loss        | -0.00032248942 |\n",
      "| loss/value_loss         | 0.0645526      |\n",
      "| misc/explained_variance | 0.0757         |\n",
      "| misc/nupdates           | 13             |\n",
      "| misc/serial_timesteps   | 1664           |\n",
      "| misc/time_elapsed       | 15.8           |\n",
      "| misc/total_timesteps    | 6656           |\n",
      "--------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 867           |\n",
      "| eprewmean               | -20.8         |\n",
      "| fps                     | 490           |\n",
      "| loss/approxkl           | 0.0002730407  |\n",
      "| loss/clipfrac           | 0.00390625    |\n",
      "| loss/policy_entropy     | 1.7812308     |\n",
      "| loss/policy_loss        | -0.0017034849 |\n",
      "| loss/value_loss         | 0.046707653   |\n",
      "| misc/explained_variance | 0.0493        |\n",
      "| misc/nupdates           | 14            |\n",
      "| misc/serial_timesteps   | 1792          |\n",
      "| misc/time_elapsed       | 16.9          |\n",
      "| misc/total_timesteps    | 7168          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| eplenmean               | 867           |\n",
      "| eprewmean               | -20.8         |\n",
      "| fps                     | 497           |\n",
      "| loss/approxkl           | 0.0004713135  |\n",
      "| loss/clipfrac           | 0.0           |\n",
      "| loss/policy_entropy     | 1.7771268     |\n",
      "| loss/policy_loss        | -0.0017133979 |\n",
      "| loss/value_loss         | 0.051062685   |\n",
      "| misc/explained_variance | 0.00401       |\n",
      "| misc/nupdates           | 15            |\n",
      "| misc/serial_timesteps   | 1920          |\n",
      "| misc/time_elapsed       | 17.9          |\n",
      "| misc/total_timesteps    | 7680          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 867           |\n",
      "| eprewmean               | -20.8         |\n",
      "| fps                     | 521           |\n",
      "| loss/approxkl           | 0.0010636343  |\n",
      "| loss/clipfrac           | 0.056152344   |\n",
      "| loss/policy_entropy     | 1.7623156     |\n",
      "| loss/policy_loss        | -0.0028279447 |\n",
      "| loss/value_loss         | 0.085700095   |\n",
      "| misc/explained_variance | 0.025         |\n",
      "| misc/nupdates           | 16            |\n",
      "| misc/serial_timesteps   | 2048          |\n",
      "| misc/time_elapsed       | 18.9          |\n",
      "| misc/total_timesteps    | 8192          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 867           |\n",
      "| eprewmean               | -20.8         |\n",
      "| fps                     | 498           |\n",
      "| loss/approxkl           | 0.0003395166  |\n",
      "| loss/clipfrac           | 0.0           |\n",
      "| loss/policy_entropy     | 1.7457435     |\n",
      "| loss/policy_loss        | -0.0014970499 |\n",
      "| loss/value_loss         | 0.052464306   |\n",
      "| misc/explained_variance | 0.0768        |\n",
      "| misc/nupdates           | 17            |\n",
      "| misc/serial_timesteps   | 2176          |\n",
      "| misc/time_elapsed       | 19.9          |\n",
      "| misc/total_timesteps    | 8704          |\n",
      "-------------------------------------------\n",
      "Stepping environment...\n",
      "--------------------------------------------\n",
      "| eplenmean               | 867            |\n",
      "| eprewmean               | -20.8          |\n",
      "| fps                     | 502            |\n",
      "| loss/approxkl           | 0.0002494865   |\n",
      "| loss/clipfrac           | 0.0            |\n",
      "| loss/policy_entropy     | 1.7352746      |\n",
      "| loss/policy_loss        | -0.00061067427 |\n",
      "| loss/value_loss         | 0.04438302     |\n",
      "| misc/explained_variance | 0.119          |\n",
      "| misc/nupdates           | 18             |\n",
      "| misc/serial_timesteps   | 2304           |\n",
      "| misc/time_elapsed       | 20.9           |\n",
      "| misc/total_timesteps    | 9216           |\n",
      "--------------------------------------------\n",
      "Stepping environment...\n",
      "-------------------------------------------\n",
      "| eplenmean               | 867           |\n",
      "| eprewmean               | -20.8         |\n",
      "| fps                     | 500           |\n",
      "| loss/approxkl           | 4.795634e-05  |\n",
      "| loss/clipfrac           | 0.0           |\n",
      "| loss/policy_entropy     | 1.7456135     |\n",
      "| loss/policy_loss        | -0.0005875508 |\n",
      "| loss/value_loss         | 0.050125826   |\n",
      "| misc/explained_variance | 0.145         |\n",
      "| misc/nupdates           | 19            |\n",
      "| misc/serial_timesteps   | 2432          |\n",
      "| misc/time_elapsed       | 22            |\n",
      "| misc/total_timesteps    | 9728          |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v0 --num_timesteps=1e4 --save_path=./models/Pong_20M_ppo2 --log_path=./logs/Pong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2020-05-11-16-18-47-074034\n",
      "env_type: atari\n",
      "Training ppo2 on atari:PongNoFrameskip-v0 with arguments \n",
      "{'nsteps': 128, 'nminibatches': 4, 'lam': 0.95, 'gamma': 0.99, 'noptepochs': 4, 'log_interval': 1, 'ent_coef': 0.01, 'lr': <function atari.<locals>.<lambda> at 0x7f26893c39e0>, 'cliprange': 0.1, 'load_path': './models/Pong_20M_ppo2', 'network': 'cnn'}\n",
      "input shape is (84, 84, 4)\n",
      "2020-05-11 16:18:49.304445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-05-11 16:18:49.320904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.321414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2020-05-11 16:18:49.321570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:18:49.322987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:18:49.324291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-05-11 16:18:49.324509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-05-11 16:18:49.325942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-05-11 16:18:49.326768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-05-11 16:18:49.329802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-11 16:18:49.329992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.330588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.330842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-05-11 16:18:49.331101: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-11 16:18:49.353962: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2020-05-11 16:18:49.354406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55819a43cb30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-11 16:18:49.354430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-11 16:18:49.354631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.355148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2020-05-11 16:18:49.355216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:18:49.355236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:18:49.355251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-05-11 16:18:49.355266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-05-11 16:18:49.355281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-05-11 16:18:49.355295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-05-11 16:18:49.355310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-11 16:18:49.355399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.355954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.356290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-05-11 16:18:49.356329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:18:49.407762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-05-11 16:18:49.407792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2020-05-11 16:18:49.407800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2020-05-11 16:18:49.407962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.408267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.408516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:18:49.408744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2020-05-11 16:18:49.410237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55819b2b50f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-11 16:18:49.410264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1\n",
      "Running trained model\n",
      "2020-05-11 16:18:51.005881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:18:51.166422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "episode_rew=-21.0\n",
      "episode_rew=-20.0\n",
      "episode_rew=-20.0\n",
      "episode_rew=-19.0\n"
     ]
    }
   ],
   "source": [
    "!python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v0 --num_timesteps=0 --load_path=./models/Pong_20M_ppo2 --play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-11 16:19:08--  https://github.com/PacktWorkshops/The-Reinforcement-Learning-Workshop/blob/master/Chapter04/pong_20M_ppo2.tar.gz?raw=true\n",
      "Resolving github.com (github.com)... 140.82.118.3\n",
      "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/PacktWorkshops/The-Reinforcement-Learning-Workshop/raw/master/Chapter04/pong_20M_ppo2.tar.gz [following]\n",
      "--2020-05-11 16:19:09--  https://github.com/PacktWorkshops/The-Reinforcement-Learning-Workshop/raw/master/Chapter04/pong_20M_ppo2.tar.gz\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/PacktWorkshops/The-Reinforcement-Learning-Workshop/master/Chapter04/pong_20M_ppo2.tar.gz [following]\n",
      "--2020-05-11 16:19:09--  https://raw.githubusercontent.com/PacktWorkshops/The-Reinforcement-Learning-Workshop/master/Chapter04/pong_20M_ppo2.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.128.133, 151.101.64.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18284569 (17M) [application/octet-stream]\n",
      "Saving to: ‘pong_20M_ppo2.tar.gz’\n",
      "\n",
      "pong_20M_ppo2.tar.g 100%[===================>]  17,44M  15,1MB/s    in 1,2s    \n",
      "\n",
      "2020-05-11 16:19:11 (15,1 MB/s) - ‘pong_20M_ppo2.tar.gz’ saved [18284569/18284569]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O pong_20M_ppo2.tar.gz https://github.com/PacktWorkshops/The-Reinforcement-Learning-Workshop/blob/master/Chapter04/pong_20M_ppo2.tar.gz?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pong_20M_ppo2/ckpt-1.data-00000-of-00001\n",
      "pong_20M_ppo2/ckpt-1.index\n",
      "pong_20M_ppo2/\n",
      "pong_20M_ppo2/checkpoint\n"
     ]
    }
   ],
   "source": [
    "!tar xvzf pong_20M_ppo2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2020-05-11-16-19-18-194254\n",
      "env_type: atari\n",
      "Training ppo2 on atari:PongNoFrameskip-v0 with arguments \n",
      "{'nsteps': 128, 'nminibatches': 4, 'lam': 0.95, 'gamma': 0.99, 'noptepochs': 4, 'log_interval': 1, 'ent_coef': 0.01, 'lr': <function atari.<locals>.<lambda> at 0x7f1c91994950>, 'cliprange': 0.1, 'load_path': './pong_20M_ppo2', 'network': 'cnn'}\n",
      "input shape is (84, 84, 4)\n",
      "2020-05-11 16:19:20.445156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-05-11 16:19:20.460675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.460956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2020-05-11 16:19:20.461143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:19:20.462636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:19:20.463881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-05-11 16:19:20.464122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-05-11 16:19:20.465510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-05-11 16:19:20.466348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-05-11 16:19:20.469364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-11 16:19:20.469530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.469859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.470079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-05-11 16:19:20.470393: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-11 16:19:20.493956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2020-05-11 16:19:20.494186: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bdb90ac750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-11 16:19:20.494209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-11 16:19:20.494427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.494694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2020-05-11 16:19:20.494767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:19:20.494789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:19:20.494808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-05-11 16:19:20.494828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-05-11 16:19:20.494847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-05-11 16:19:20.494866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-05-11 16:19:20.494886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-11 16:19:20.494969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.495259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.495473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-05-11 16:19:20.495522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-05-11 16:19:20.537306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-05-11 16:19:20.537336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2020-05-11 16:19:20.537343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2020-05-11 16:19:20.537520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.537848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.538161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-11 16:19:20.538422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2020-05-11 16:19:20.540099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bdb9f09850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-11 16:19:20.540149: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1\n",
      "Running trained model\n",
      "2020-05-11 16:19:22.014722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-05-11 16:19:22.172007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "!python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v0 --num_timesteps=0 --load_path=./pong_20M_ppo2 --play"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
