# Chapter 02: Markov Decision Processes and Bellman Equations

In this Chapter you will learn more in details about MDPs and Bellman Equations. 

## Examples

Examples of this chapter are:

- Student MDP: [link](Examples/Student_MDP.ipynb)

In this example you will practice with MDPs, you will learn how to calculate the value function for a given policy and how to calculate the action value function.

## Exercises

Here you can find all exercises of this chapter:

- Bellman Equation for MRPs: [link](Exercise02_01/Exercise02_01.ipynb)
- Solving MDPs: Linear Programming: [link](Exercise02_02/Exercise02_02.ipynb)

In these exercises you will practice with Markov Reward Processes (MRPs) and with the Linear Programming solution of Markov Decision Processes.

## Activity

The activity of this chapter is:

- Gridworld: [link](Activity02_01/Activity02_01.ipynb)

In this activity you will learn how to formalize a classic RL environment (Gridworld) composed of good states and bad states. The objective is to solve the environment finding the state-value function for all states using Bellman Equations.
