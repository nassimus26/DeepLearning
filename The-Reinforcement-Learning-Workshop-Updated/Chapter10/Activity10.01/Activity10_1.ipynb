{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Activity10_1.ipynb","provenance":[{"file_id":"1YgSbe2q6LwhVdlHed2pIzWpxvAxNFa7T","timestamp":1588475528250}],"collapsed_sections":[],"authorship_tag":"ABX9TyPppQbye1QwljPjJDt5/x+f"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nOFOZNtiLna6","colab_type":"code","colab":{}},"source":["import gym \n","import random\n","import numpy as np\n","from collections import deque\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.optimizers import RMSprop\n","import datetime"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QCBSatZmcuWn","colab_type":"code","colab":{}},"source":["np.random.seed(168)\n","tf.random.set_seed(168)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wfjKpXoLsmg","colab_type":"code","colab":{}},"source":["class DQN():\n","    def __init__(self, env, batch_size=64, max_experiences=5000):\n","        self.env = env\n","        self.input_size = self.env.observation_space.shape[0]\n","        self.action_size = self.env.action_space.n\n","        self.max_experiences = max_experiences\n","        self.memory = deque(maxlen=self.max_experiences)\n","        self.batch_size = batch_size\n","        self.gamma = 1.0\n","        self.epsilon = 1.0\n","        self.epsilon_min = 0.01\n","        self.epsilon_decay = 0.995\n","        \n","        self.model = self.build_model()\n","        self.target_model = self.build_model()\n","                \n","    def build_model(self):\n","        model = Sequential()\n","        model.add(Conv2D(32, 8, (4,4), activation='relu', padding='valid', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n","        model.add(Conv2D(64, 4, (2,2), activation='relu', padding='valid'))\n","        model.add(Conv2D(64, 3, (1,1), activation='relu', padding='valid'))\n","        model.add(Flatten())\n","        model.add(Dense(256, activation='relu'))\n","        model.add(Dense(self.action_size))\n","        model.compile(loss='mse', optimizer=RMSprop(lr=0.00025, epsilon=self.epsilon_min), metrics=['accuracy'])\n","\n","        return model\n","            \n","    def get_action(self, state):\n","        if np.random.random() <= self.epsilon:\n","            return self.env.action_space.sample()\n","        else:\n","            return np.argmax(self.model.predict(tf.expand_dims(state, 0)))\n","\n","    def add_experience(self, state, action, reward, next_state, done):\n","        self.memory.append((state, action, reward, next_state, done))\n","        self.update_epsilon()\n","\n","    def replay(self, episode):\n","        x_batch, y_batch = [], []\n","        minibatch = random.sample(self.memory, min(len(self.memory), self.batch_size))\n","        \n","        for state, action, reward, next_state, done in minibatch:\n","            y_target = self.target_model.predict(tf.expand_dims(state, 0))\n","            y_target[0][action] = reward if done else reward + self.gamma * np.max(self.model.predict(tf.expand_dims(next_state, 0))[0])\n","            x_batch.append(state)\n","            y_batch.append(y_target[0])\n","\n","        self.model.fit(np.array(x_batch), np.array(y_batch), batch_size=len(x_batch), verbose=0)  \n","\n","    def update_epsilon(self):\n","        self.epsilon = max(self.epsilon_min, self.epsilon_decay * self.epsilon)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDwTwc7VPM0F","colab_type":"code","colab":{}},"source":["def initialize_env(env):\n","  initial_state = env.reset()\n","  initial_done_flag = False\n","  initial_rewards = 0\n","  return initial_state, initial_done_flag, initial_rewards"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xj9Qq-n4I7_w","colab_type":"code","colab":{}},"source":["def preprocess_state(image, img_size):\n","    img_temp = image[31:195]\n","    img_temp = tf.image.rgb_to_grayscale(img_temp)\n","    img_temp = tf.image.resize(img_temp, [img_size, img_size],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    img_temp = tf.cast(img_temp, tf.float32)\n","    return img_temp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZbzN_AZPPdx","colab_type":"code","colab":{}},"source":["def play_game(agent, state, done, rewards):    \n","    while not done:\n","        action = agent.get_action(state)\n","        next_state, reward, done, _ = env.step(action)\n","\n","        next_state = preprocess_state(next_state, IMG_SIZE)\n","        \n","        agent.add_experience(state, action, reward, next_state, done)\n","\n","        state = next_state\n","        rewards += reward   \n","    return rewards"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Axc6Pa3xPvn6","colab_type":"code","colab":{}},"source":["def train_agent(env, episodes, agent):\n","  from collections import deque\n","  import numpy as np\n","\n","  scores = deque(maxlen=100)\n","\n","  for episode in range(episodes):\n","    state, done, rewards = initialize_env(env) \n","    state = preprocess_state(state, IMG_SIZE)\n","\n","    rewards = play_game(agent, state, done, rewards)\n","    scores.append(rewards)\n","    mean_score = np.mean(scores)\n","\n","    if episode % 50 == 0:\n","        print(f'[Episode {episode}] - Average Score: {mean_score}')\n","        agent.target_model.set_weights(agent.model.get_weights())\n","        agent.target_model.save_weights(f'dqn/dqn_model_weights_{episode}')\n","\n","    agent.replay(episode)\n","\n","  print(f\"Average Score: {np.mean(scores)}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yc3Iz-AcPxyG","colab_type":"code","outputId":"baffc360-6bd8-47fa-fe3b-dcb7662dabb9","executionInfo":{"status":"ok","timestamp":1588587428807,"user_tz":-600,"elapsed":25991136,"user":{"displayName":"Anthony So","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYepcJQjaVrQ1i01LEROgsJ738vi03JrR51Ryb3w=s64","userId":"11809607246124237079"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["env = gym.make('BreakoutDeterministic-v4')\n","IMG_SIZE = 84\n","SEQUENCE = 4\n","agent = DQN(env)\n","episodes = 50\n","train_agent(env, episodes, agent)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Episode 0] - Average Score: 3.0\n","Average Score: 0.59\n"],"name":"stdout"}]}]}
